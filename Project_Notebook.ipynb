{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préambule\n",
    "\n",
    "## Introduction & Contexte\n",
    "\n",
    "Ce projet a été réalisé par 3 étudiants de Master 1 à l'ENSAE, dans le cadre du cours \"Python for Data Science\". L'idée de ce projet vient d'une intuition que nous avons eu selon laquelle il était possible de prédire le succès d'un jeu vidéo auprès des utilisateurs à partir de certaines de ses caractéristiques. L'objectif principal de ce travail est donc de tenter de vérifier ou infirmer cette intuition à l'aide de techniques statistiques de traitement de données. \n",
    "\n",
    "De plus, nous voulions y incorporer une partie plus originale (traitement d'images...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des modules \n",
    "\n",
    "## Modules de webscrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# là on importe les packages\n",
    "import requests \n",
    "import urllib\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des modules de Visualisation & Modélisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Là on importe les autres packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: numpy\n",
      "Version: 1.20.3\n",
      "Summary: NumPy is the fundamental package for array computing with Python.\n",
      "Home-page: https://www.numpy.org\n",
      "Author: Travis E. Oliphant et al.\n",
      "Author-email: \n",
      "License: BSD\n",
      "Location: /opt/anaconda3/lib/python3.9/site-packages\n",
      "Requires: \n",
      "Required-by: tifffile, tables, statsmodels, seaborn, scipy, scikit-learn, scikit-image, PyWavelets, pyerfa, patsy, pandas, numexpr, numba, mkl-random, mkl-fft, matplotlib, imageio, imagecodecs, h5py, daal4py, Bottleneck, bokeh, bkcharts, astropy\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/ Récupération des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/A Webscrapping des titres des jeux vidéos sur Wikipédia\n",
    "\n",
    "A partir du site Wikipédia, nous allons récupérer les titres de tous les jeux vidéos sortis depuis l'année 2000. Par exemple, depuis l'URL : https://en.wikipedia.org/wiki/Category:2023_video_games nous avons accès à la liste de la quasi-totalité des jeux vidéos sortis en 2023. Nous allons donc modifier l'URL pour chaque année et constituer une liste (Liste_VG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#response = requests.get(url=\"https://en.wikipedia.org/wiki/Category:2022_video_games\", params = {\"title\" : \"Dome Keeper\"})\n",
    "requests.get(url=\"https://en.wikipedia.org/wiki/Category:2022_video_games\")\n",
    "soup = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "title = soup.find(id=\"firstHeading\")\n",
    "print(title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\"><span class=\"mw-page-title-namespace\">Category</span><span class=\"mw-page-title-separator\">:</span><span class=\"mw-page-title-main\">2022 video games</span></h1>\n"
     ]
    }
   ],
   "source": [
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/B Récupération des notes des jeux\n",
    "\n",
    "L'objectif de cette partie est d'extraire du site \"Métacritic\", un site spécialisé qui répertorie les avis de professionnels et d'utilisateurs sur les nouvelles sorties jeux vidéos. Pour chaque jeu dans la base de données du site, une note sur 100 est attribuée (moyenne des reviews de sites spécialisés jeux vidéos) et une note sur 10 attribuée par les utilisateurs du site. Nous allons ici récupérer pour chaque jeu ses notes Métacritic qui deviendront les variables que nous tenteront de prédire par la suite. \n",
    "\n",
    "On remarque que l'on peut atteindre la review du jeu à partir de l'URL, il suffit d'indiquer le titre du jeu dans l'URL, en faisant attention aux espaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    }
   ],
   "source": [
    "#URL du site : https://www.metacritic.com/game/\n",
    "#URL d'une recherche : https://www.metacritic.com/search/gran%20theft%20auto/\n",
    "#URL d'une review : https://www.metacritic.com/game/grand-theft-auto-v/\n",
    "#URL d'une review d'un autre site spécialisé : https://www.ign.com/games/grand-theft-auto-v\n",
    "\n",
    "#Base URL de toutes les reviews\n",
    "URL = \"https://www.metacritic.com/game/\"\n",
    "URLbis = \"https://www.metacritic.com/game/grand-theft-auto-v/\"\n",
    "user_agent = {'User-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'}\n",
    "site = requests.get(URLbis, user_agent)\n",
    "\n",
    "print(site.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html><head><title>IGN Error 403 - Unavailable (IFW-U01)</title><link href=\"https://fonts.googleapis.com/css?family=Montserrat:400,700,800\" rel=\"stylesheet\" /><link rel=\"StyleSheet\" href=\"https://synthetics.ign.com/css/error_page.css?bg=F06449\" type=\"text/css\" /><meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"><script type=\"text/javascript\">function qg(){var h=Math.floor(Math.random()*quotes.length)+0;document.getElementById(\"qb\").innerHTML=quotes[h];} var quotes=[\"<h2>&ldquo;Aren't you a little short for a stormtrooper?&rdquo;</h2><h3>&mdash;Leia Organa</h3>\",\"<h2>&ldquo;I am altering the deal, pray I do not alter it further.&rdquo;</h2><h3>&mdash;Darth Vader</h3>\",\"<h2>&ldquo;No! I don't think he likes you at all... No, I don't like you either.&rdquo;</h2><h3>&mdash;C-3PO</h3>\",\"<h2>&ldquo;I'm Luke Skywalker and I'm here to rescue you!&rdquo;</h2><h3>&mdash;Luke Skywalker</h3>\",\"<h2>&ldquo;I recognized your foul stench when I was brought on board.&rdquo;</h2><h3>&mdash;Leia Organa</h3>\",\"<h2>&ldquo;Why was she up there this whole time?!&rdquo;</h2><h3>&mdash;Okoye</h3>\",\"<h2>&ldquo;I'm sorry. Earth is closed today. So pack it up, and get out of here.&rdquo;</h2><h3>&mdash;Tony Stark</h3>\",\"<h2>&ldquo;Get over here!&rdquo;</h2><h3>&mdash;Scorpion</h3>\",\"<h2>&ldquo;It's easy to forget what a sin is in the middle of a battlefield.&rdquo;</h2><h3>&mdash;Solid Snake</h3>\",\"<h2>&ldquo;I used to be an adventurer like you, until I took an arrow to the knee.&rdquo;</h2><h3>&mdash;Town Guard</h3>\"];window.onload=qg;</script> </head><body><div id=\"w\"> <section class=\"l\"><div class=\"logo\"> <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"#fff\" fill-rule=\"evenodd\" width=\"182\" height=\"55\" viewBox=\"0 0 182 55\"><path d=\"M97.3 32.3v-9.9h26.4a5 5 0 0 1 4.9 4.9V39c0 6-4.9 11-11 11h-17a22.6 22.6 0 1 1 .1-45.2H127v10.4h-26.2c-6.7 0-12.3 5.4-12.3 12.2 0 6.7 5.5 12.2 12.3 12.2h17.5v-7.3h-21zM74.5 4.7V50H69a4.8 4.8 0 0 1-4.8-4.8V4.7h10.3zm102.4 0a5 5 0 0 1 4.9 4.9v30a11 11 0 0 1-11 10.9h-.2c-4 0-7.4-2-9.3-5.2L144 14.8a.7.7 0 0 0-.6-.3c-.3 0-.5.1-.6.4a.6.6 0 0 0-.1.3V50h-5.5a4.8 4.8 0 0 1-4.8-4.8v-30a11 11 0 0 1 11-11h.1c4 0 7.5 2.2 9.4 5.4L170.2 40c.2.3.4.4.6.4a.7.7 0 0 0 .6-.4.6.6 0 0 0 .1-.3V4.8h5.5zM12.5 17.6c-2.7.3-5.1.7-7.3 1.2A24.2 24.2 0 0 1 18.9 5c-.5 2.2-.9 4.6-1.2 7.3a18 18 0 0 0-5.2 5.2zm25-5.2c-.3-2.7-.7-5.1-1.2-7.3a24.2 24.2 0 0 1 13.8 13.7 65 65 0 0 0-7.4-1.2 18 18 0 0 0-5.1-5.2zM17.8 42.5c.3 2.7.7 5.1 1.2 7.3A24.2 24.2 0 0 1 5.2 36.1c2.1.5 4.6.9 7.3 1.2a18.2 18.2 0 0 0 5.2 5.2zm25.1-5.2c2.7-.3 5.1-.7 7.3-1.2a24.2 24.2 0 0 1-13.8 13.7c.5-2.1 1-4.6 1.3-7.2v-.1a18.2 18.2 0 0 0 5.1-5.2h.1zM55 23v9a46.8 46.8 0 0 1-14 3l-6.8-7.5L41 20a7.4 7.4 0 0 1 1.2.1c2.2.2 8.6 1 12.8 3zm-40.7-3 6.7 7.5-6.7 7.6a7.8 7.8 0 0 1-1.4-.2 47 47 0 0 1-12.7-3V23c4.3-2 10.8-2.7 12.9-3a7.5 7.5 0 0 1 1.2-.1zm5.8 20.8 7.5-6.7 7.6 6.7a7.7 7.7 0 0 1-.2 1.5c-.2 2-1 8.4-3 12.6h-8.8a46 46 0 0 1-3-12.8 7.4 7.4 0 0 1-.1-1.3zm3-40.6h9c2 4.2 2.7 10.4 3 12.6a7.7 7.7 0 0 1 0 1.4l-7.5 6.7-7.5-6.7a7.4 7.4 0 0 1 .1-1.2c.2-2.2 1-8.6 3-12.8z\"/></svg></div><h1>Error 403 - Unavailable (IFW-U01)</h1><p>Sorry but something about this request looked a bit suspicious, and we block suspicious stuff.</p> <a class=\"cta s\" href=\"http://www.ign.com\">Back to IGN</a> <a class=\"cta aq\" href=\"#\" onclick=\"qg()\">Another Quote</a > </section> <section class=\"r\" id=\"qb\"><h2>QUOTE</h2><h3>&mdash;AUTHOR</h3> </section></div></body></html>\n"
     ]
    }
   ],
   "source": [
    "print(site.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests-html\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "Collecting parse\n",
      "  Downloading parse-1.20.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting pyquery\n",
      "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting fake-useragent\n",
      "  Downloading fake_useragent-1.4.0-py3-none-any.whl (15 kB)\n",
      "Collecting pyppeteer>=0.0.14\n",
      "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting w3lib\n",
      "  Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (from requests-html) (2.26.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /opt/anaconda3/lib/python3.9/site-packages (from pyppeteer>=0.0.14->requests-html) (1.26.7)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /opt/anaconda3/lib/python3.9/site-packages (from pyppeteer>=0.0.14->requests-html) (4.8.1)\n",
      "Collecting websockets<11.0,>=10.0\n",
      "  Downloading websockets-10.4-cp39-cp39-macosx_10_9_x86_64.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2021 in /opt/anaconda3/lib/python3.9/site-packages (from pyppeteer>=0.0.14->requests-html) (2021.10.8)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /opt/anaconda3/lib/python3.9/site-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /opt/anaconda3/lib/python3.9/site-packages (from pyppeteer>=0.0.14->requests-html) (4.62.3)\n",
      "Collecting pyee<9.0.0,>=8.1.0\n",
      "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.6.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.9/site-packages (from bs4->requests-html) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->bs4->requests-html) (2.2.1)\n",
      "Collecting importlib-resources>=5.0\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: lxml>=2.1 in /opt/anaconda3/lib/python3.9/site-packages (from pyquery->requests-html) (4.6.3)\n",
      "Collecting cssselect>=1.2.0\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests->requests-html) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests->requests-html) (3.2)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=7e53fdcf6123f70b8296683c49cf10c00437d214d96991a0d5884f4fb55d3ceb\n",
      "  Stored in directory: /Users/tomrossa/Library/Caches/pip/wheels/73/2b/cb/099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: websockets, pyee, importlib-resources, cssselect, w3lib, pyquery, pyppeteer, parse, fake-useragent, bs4, requests-html\n",
      "Successfully installed bs4-0.0.1 cssselect-1.2.0 fake-useragent-1.4.0 importlib-resources-6.1.1 parse-1.20.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-2.0.0 requests-html-0.10.0 w3lib-2.1.2 websockets-10.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests-html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "response = session.get(URLbis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = response.html.find('body > div > div.c-layoutDefault')\n",
    "#links = response.html.find('.c-layoutDefault.c-layoutDefault_page')\n",
    "#links = response.html.find('.c-productScoreInfo_scoreNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
